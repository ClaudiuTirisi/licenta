{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "537c00f6-5e69-4131-8dc8-69bbde86286d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/muse-mamba/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"metrics\")\n",
    "sys.path.append(\"external\")\n",
    "sys.path.append(\"external/vqgan-taming\")\n",
    "from masked_model import MaskedModel, SequenceModelWrapper\n",
    "from lowres_trainer import LowResTrainer\n",
    "\n",
    "from vqgan import VQModel\n",
    "\n",
    "from masked_transformer import Transformer\n",
    "\n",
    "from muse_maskgit_pytorch import TransformerBlocks\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "\n",
    "import math\n",
    "\n",
    "from masked_attn_mamba import MambaAttn\n",
    "from vqganconfig import vqgan_config\n",
    "\n",
    "from muse_maskgit_pytorch import MaskGit, MaskGitTransformer\n",
    "\n",
    "from custom_datasets import ImageTextNameDataset\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from mambaCText import MambaCText\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a73b477-fb50-4749-9293-af3cfad316bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/muse-mamba/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/miniconda3/envs/muse-mamba/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "Restored from  models/pretrained-vqgan.ckpt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vae = VQModel(**vqgan_config)\n",
    "vae.init_from_ckpt(path = \"models/pretrained-vqgan.ckpt\")\n",
    "\n",
    "_ = vae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "004bb494-7738-45e4-97e0-f73fde5f1932",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MambaAttn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m transformer \u001b[38;5;241m=\u001b[39m MaskGitTransformer(\n\u001b[0;32m----> 2\u001b[0m     actual_model \u001b[38;5;241m=\u001b[39m \u001b[43mMambaAttn\u001b[49m(\n\u001b[1;32m      3\u001b[0m       token_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2048\u001b[39m,\n\u001b[1;32m      4\u001b[0m       depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m,\n\u001b[1;32m      5\u001b[0m       d_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m      6\u001b[0m     ),\n\u001b[1;32m      7\u001b[0m     num_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16384\u001b[39m,       \u001b[38;5;66;03m# must be same as codebook size above\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     seq_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m16\u001b[39m,            \u001b[38;5;66;03m# must be equivalent to fmap_size ** 2 in vae\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2048\u001b[39m,                \u001b[38;5;66;03m# model dimension\u001b[39;00m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m base_maskgit \u001b[38;5;241m=\u001b[39m MaskGit(\n\u001b[1;32m     13\u001b[0m     transformer \u001b[38;5;241m=\u001b[39m transformer, \u001b[38;5;66;03m# transformer\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     image_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m,          \u001b[38;5;66;03m# image size\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     no_mask_token_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.25\u001b[39m,\n\u001b[1;32m     18\u001b[0m )\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     20\u001b[0m base_maskgit\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../results/original-transformer_results-part2/maskgit.1099999.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MambaAttn' is not defined"
     ]
    }
   ],
   "source": [
    "transformer = MaskGitTransformer(\n",
    "    actual_model = MambaAttn(\n",
    "      token_size = 2048,\n",
    "      depth = 12,\n",
    "      d_state = 16,\n",
    "    ),\n",
    "    num_tokens = 16384,       # must be same as codebook size above\n",
    "    seq_len = 16*16,            # must be equivalent to fmap_size ** 2 in vae\n",
    "    dim = 2048,                # model dimension\n",
    ")\n",
    "\n",
    "base_maskgit = MaskGit(\n",
    "    transformer = transformer, # transformer\n",
    "    image_size = 256,          # image size\n",
    "    cond_drop_prob = 0.25,     # conditional dropout, for classifier free guidance\n",
    "    self_token_critic = True,\n",
    "    no_mask_token_prob = 0.25,\n",
    ").cuda()\n",
    "\n",
    "base_maskgit.load(\"../results/original-transformer_results-part2/maskgit.1099999.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08aa1eb4-f801-487c-b8f3-751184de9d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds = ImageTextNameDataset(folder = \"../dataset/cc3m-valid-original\", image_size = 256)\n",
    "batch_size = 16\n",
    "valid_dl = DataLoader(valid_ds, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c9b608b-1e32-4cca-bd7c-0d4a6e08e90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13443"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "638b4832-e0e0-41d9-bede-32d3084da4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 841/841 [1:01:30<00:00,  4.39s/it]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for _, texts, names in tqdm(valid_dl):\n",
    "        batch_size = len(texts)\n",
    "        images = vae.decode_from_ids(base_maskgit.generate(texts = list(texts), fmap_size = 16, cond_scale = 4), batch_size = batch_size, fmap_size = 16)\n",
    "        for i in range(batch_size):\n",
    "            torchvision.utils.save_image(images[i], open(\"../valid-generated-transformer-12/\" + names[i] + \".jpg\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77007bfd-43e8-4f66-8c26-3007ead61de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a folder of resized 256x256 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0600b63-3544-449e-9d69-8305bf0cf5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 841/841 [01:52<00:00,  7.46it/s]\n"
     ]
    }
   ],
   "source": [
    "for resized_images, texts, names in tqdm(valid_dl):\n",
    "    batch_size = len(texts)\n",
    "    for i in range(batch_size):\n",
    "        torchvision.utils.save_image(resized_images[i], open(\"../dataset/cc3m-valid-256x256-images/\" + names[i] + \".jpg\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaa0fe3b-a47c-4b62-a1da-93272fc15a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a folder of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e68e17db-7924-4993-a8e3-3e55cb060354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 841/841 [02:15<00:00,  6.22it/s]\n"
     ]
    }
   ],
   "source": [
    "for resized_images, texts, names in tqdm(valid_dl):\n",
    "    batch_size = len(texts)\n",
    "    for i in range(batch_size):\n",
    "        path = \"../dataset/cc3m-valid-256x256-texts/\" + names[i] + \".txt\"\n",
    "        with open(path, \"w\") as f:\n",
    "            f.write(texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5d1a10-708c-4bea-9716-6d8d918778f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

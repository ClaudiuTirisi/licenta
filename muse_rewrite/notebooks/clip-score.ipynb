{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--batch-size'], dest='batch_size', nargs=None, const=None, default=50, type=<class 'int'>, choices=None, help='Batch size to use', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument(\"--batch-size\", type = int, default = 50, help ='Batch size to use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--clip-model'], dest='clip_model', nargs=None, const=None, default='ViT-B/32', type=<class 'str'>, choices=None, help='CLIP model to use', metavar=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument(\"--clip-model\", type = str, default = \"ViT-B/32\", help=\"CLIP model to use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--num-workers'], dest='num_workers', nargs=None, const=None, default=None, type=<class 'int'>, choices=None, help='Number of processes to use for data loading. Default to `min(8, num_cpus)`', metavar=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument(\"--num-workers\", type=int, help=(\"Number of processes to use for data loading. Default to `min(8, num_cpus)`\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--device'], dest='device', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='Device to use. Like cuda, cuda:0 or cpu', metavar=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument(\"--device\", type = str, default = None, help = \"Device to use. Like cuda, cuda:0 or cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--real_flag'], dest='real_flag', nargs=None, const=None, default='img', type=<class 'str'>, choices=None, help='The modality of real path. Default to img', metavar=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument(\"--real_flag\", type = str, default = \"img\", help = \"The modality of real path. Default to img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--fake_flag'], dest='fake_flag', nargs=None, const=None, default='txt', type=<class 'str'>, choices=None, help='The modality of fake path. Defaults to txt', metavar=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument(\"--fake_flag\", type = str, default = \"txt\", help = \"The modality of fake path. Defaults to txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--real_path'], dest='real_path', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='Paths to the generated images or .npz statistic files', metavar=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument(\"--real_path\", type = str, help = \"Paths to the generated images or .npz statistic files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--fake_path'], dest='fake_path', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='Paths to generated iamges or .npz statistic files', metavar=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument(\"--fake_path\", type=str, help=\"Paths to generated iamges or .npz statistic files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_EXTENSIONS = {\"bmp\", \"jpg\", \"jpeg\", \"pgm\", \"png\", \"ppm\", \"tif\", \"tiff\", \"webp\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_EXTENSIONS = {\"txt\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyDataset(Dataset):\n",
    "  FLAGS = [\"img\", \"txt\"]\n",
    "  def __init__(\n",
    "    self, \n",
    "    real_path,\n",
    "    fake_path,\n",
    "    real_flag = \"img\",\n",
    "    fake_flag = \"img\",\n",
    "    transform = None,\n",
    "    tokenizer = None\n",
    "  ):\n",
    "    super().__init__()\n",
    "    assert real_flag in self.FLAGS and fake_flag in self.FLAGS, \"CLIP only supports img and txt modalities\"\n",
    "\n",
    "    self.real_folder = self._combine_without_prefix(real_path)\n",
    "    self.real_flag = real_flag\n",
    "    self.fake_folder = self._combine_without_prefix(fake_path)\n",
    "    self.fake_flag = fake_flag\n",
    "    self.transform = transform\n",
    "    self.tokenizer = tokenizer\n",
    "    assert self._check()\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.real_folder)\n",
    "  \n",
    "  def _check(self):\n",
    "    # works because real_folder and fake_folder are both sorted\n",
    "    for idx in range(len(self)):\n",
    "      real_name = self.real_folder[idx].split('.')\n",
    "      fake_name = self.fake_folder[idx].split('.')\n",
    "      if fake_name != real_name:\n",
    "        return False\n",
    "      \n",
    "    return True\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    if index >= len(self):\n",
    "      raise IndexError\n",
    "    \n",
    "    real_path = self.real_folder[index]\n",
    "    fake_path = self.fake_folder[index]\n",
    "    real_data = self._load_modality(real_path, self.real_flag)\n",
    "    fake_data = self._load_modality(fake_path, self.fake_flag)\n",
    "\n",
    "  def _load_modality(self, path, modality):\n",
    "    if modality == 'img':\n",
    "      data = self._load_img(path)\n",
    "    elif modality == 'txt':\n",
    "      data = self._load_txt(path)\n",
    "    else:\n",
    "      raise TypeError(f\"Got unexpected modality: {modality}\")\n",
    "    return data\n",
    "  \n",
    "  def _load_img(self, path):\n",
    "    img = Image.open(path)\n",
    "    if self.transform is not None:\n",
    "      img = self.transform(img)\n",
    "    return img\n",
    "  \n",
    "  def _load_txt(self, path):\n",
    "    with open(path, 'r') as fp:\n",
    "      data = fp.read()\n",
    "\n",
    "    if self.tokenizer is not None:\n",
    "      data = self.tokenizer(data).squeeze()\n",
    "\n",
    "    return data\n",
    " \n",
    "  def _combine_without_prefix(self, folder_path, prefix = '.'):\n",
    "    \"\"\"\n",
    "    Make a sorted list of all the files in a folder except for those\n",
    "    whose name starts with a given character\n",
    "    By default ignores files starting with a .\n",
    "    \"\"\"\n",
    "    folder = []\n",
    "    for name in os.listdir(folder_path):\n",
    "      if name[0] == prefix:\n",
    "        continue\n",
    "      folder.append(osp.join(folder_path, name))\n",
    "\n",
    "    folder.sort()\n",
    "    return folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_modality(model, data, flag):\n",
    "  device = next(model.parameters()).device\n",
    "  data = data.to(device)\n",
    "  if flag == 'img':\n",
    "    return model.encode_image(data)\n",
    "  if flag == 'txt':\n",
    "    return model.encode_text(data)\n",
    "  raise TypeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def calculate_clip_score(dataloader, model, real_flag, fake_flag):\n",
    "  score_acc = 0.\n",
    "  sample_num = 0.\n",
    "  # presumably some sort of maximum value of a logit?\n",
    "  logit_scale = model.logit_scale.exp()\n",
    "\n",
    "  for batch_data in tqdm(dataloader):\n",
    "    real, fake = batch_data\n",
    "    real_features = forward_modality(model, real, real_flag)\n",
    "    fake_features = forward_modality(model, fake, fake_flag)\n",
    "\n",
    "    real_features = real.features / real_features.norm(dim = 1, keepdim = True).to(torch.float32)\n",
    "    fake_features = fake_features / fake_features.norm(dim = 1, keepdim = True).to(torch.float32)\n",
    "\n",
    "    # dot product * logit_scale\n",
    "    score = logit_scale * (fake_features * real_features).sum()\n",
    "    score_acc += score\n",
    "    sample_num += real.shape[0]\n",
    "  \n",
    "  return score_acc / sample_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "  args = parser.parse_args()\n",
    "\n",
    "  if args.device is None:\n",
    "    device = [\"cpu\", \"cuda\"][torch.cuda.is_available()]\n",
    "    device = torch.device(device)\n",
    "  else:\n",
    "    device = torch.device(args.device)\n",
    "\n",
    "  if args.num_workers is None:\n",
    "    try:\n",
    "      num_cpus = len(os.sched_getaffinity(0))\n",
    "    except AttributeError:\n",
    "      num_cpus = os.cpu_count()\n",
    "\n",
    "    num_workers = min(num_cpus, 8) if num_cpus is None else 0\n",
    "  else:\n",
    "    num_workers = args.num_workers\n",
    "\n",
    "  model, preprocess = clip.load(args.clip_model, device = device)\n",
    "\n",
    "  dataset = DummyDataset(args.real_path, args.fake_path, args.real_flag, args.fake_flag, transform = preprocess, tokenizer = clip.tokenize)\n",
    "  dataloader = DataLoader(dataset, args.batch_size, num_workers = num_workers, pin_memory = True)\n",
    "\n",
    "  clip_score = calculate_clip_score(dataloader, model, args.real_flag, args.fake_flag)\n",
    "  clip_score = clip_score.cpu().item()\n",
    "  print(f\"CLIP score: {clip_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--batch-size BATCH_SIZE]\n",
      "                             [--clip-model CLIP_MODEL]\n",
      "                             [--num-workers NUM_WORKERS] [--device DEVICE]\n",
      "                             [--real_flag REAL_FLAG] [--fake_flag FAKE_FLAG]\n",
      "                             [--real_path REAL_PATH] [--fake_path FAKE_PATH]\n",
      "ipykernel_launcher.py: error: ambiguous option: --f=/home/ubuntu/.local/share/jupyter/runtime/kernel-v2-1616070NxR81qs4YjEs.json could match --fake_flag, --fake_path\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/muse/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3513: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "muse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
